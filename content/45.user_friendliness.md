## User-Friendliness

Several different entrypoints exist for research codes.
For instance, an ontology of "end-users" in science has developed that emphasizes that typically "library" codes are only used implicitly by researchers.
In this framing, library codes primarily interface with application codes, rather than with researchers.
We have taken a slightly different approach with the design and development of yt, as it exists in a middle-ground as a library used *as an application* within the scripting language Python and also as a library for more complex analysis of data.
As an outgrowth of this, we have taken particular care with the "public-facing" API of yt.
We have attempted to abstract the API enough from the data structures yt uses internally that it is useful without detailed knowledge of yt's internals.
By the same token, we have also attempted to provide low-level access to data, and to make as many of those methods accessible and usable as well.

In addition to API considerations, there are three areas that we note have additional care paid to the generation of figures, helpful error messages, and to integration with the omnipresent Jupyter environment.

### Publication-Ready Figures

Matplotlib @doi:10.5281/zenodo.7570264 is a fully-featured mechanism for generating figures, with an incredible array of options to customize formatting, appearance, rendering of fonts and glyphs, selection of colorbars, calculation of tick locations, and appropriate bounds.
This degree of flexibility provides extremely fine-grained control over the appearance of figures for publication, and Matplotlib provides a large number of output formats for even the most discerning of journals.

yt utilizes Matplotlib as its primary rendering engine for visualizations; while 3D renderings (such as those described in @sec:software-volume-rendering) typically generate raw pixel buffers that are saved as images directly, most other visualization functionality in yt relies on Matplotlib for generating images that are saved to disk.
Slices and projections are prepared as variable-resolution images that are pixelized (@sec:pixelization) into fixed resolution buffers, then provided to Matplotlib in the `imshow` function.
Phase plots utilize the `pcolormesh` function.

All of these internal plots utilize Matplotlib's "object-oriented" interface, wherein `Figure` and `Axes` objects are created directly.
yt then manages the internal state of these objects, and provides high-level access to operations that are aware of the nature of the visualizations; for instance, operations that zoom and pan, and that are unit-aware.
In the case of 2D spatial images, these are all generated as subclasses of a `PlotWindow` object, named such because it functions as a "window" onto the data, including automatically generating and managing multiple fields simultaneously.

Within the `PlotWindow` object, we set up two levels of visualization invalidation; when a characteristic of the image buffer data is changed (i.e., the viewing window, the resolution) then the *image data* is said to be invalidated.
When a characteristic of the visualization is changed (the label, the scaling of the colorbar, the colormap) then the *plot* is said to be invalidated.
This allows yt to minimize the overhead of conducting potentially expensive operations on the underlying (unprocessed) data, while maximizing its utilization of Matplotlib for generation of images.
The image buffers generated are also always available through the API, so in the common case that researchers wish to take the genrated images and perform detailed manipulations or plot layouts, they are able to do so, using the Matplotlib API they may already be familiar with.

In addition to providing data-aware operations for plot organization, a number of plot modifications are available that provide data-aware annotations.
As the plot window moves, the data-aware annotations are updated and move with the window.
For example, the process of generating vector overlays from variable-resolution data requires the same set of operations as generating a fixed resolution image buffer, so yt provides a method for overplotting vector fields.
This also requires correctly applying axis-ordering, so yt will automatically determine the appropriate x and y vectors in the image plane, and for an off-axis slice, it will generate in-plane vector fields by computing the appropriate set of dot products.
Additional data-aware operations include overplotting locations of gravitationally-bound clumps, contour plots of variable-resolution data, boundaries of data structures (such as grids in patch-based grid datasets, cells from patch and octree datasets, particle locations), streamlines, line integral convolution, and coordinate-aware annotations.

All of these figure construction and modification methods apply to cartesian ($x$, $y$, $z$) datasets, but yt also supports them for curvilinear data such as that organized spherically ($r$, $\theta$, $\phi$) and cylindrically ($r$, $z$, $\theta$).

By focusing on the utilizing low-level yt operations to facilitate high-level interactions, we can embed best practices for accessibility and visualizations at as many levels as possible.
For instance, yt provides suggested colormaps for specific fields, will apply heuristics to determine the appropriate scaling (such as symmetric logarithm) and utilize the appropriate labels and units to the data.
This allows users of yt to access both the expansive functionality of Matplotlib as well as the more domain-specific tasks available in yt.

Finally, the `cmyt` package ('colormaps from yt') also provides several colormaps that were, until yt 4.0, included in the main yt distribution.
Many of these are developed by yt contributors, typically using the [`viscm`](https://github.com/matplotlib/viscm) package, and are designed to be perceptually uniform in colorspace.

| Colormap Name | Colormap                              |
| ------------- | ------------------------------------- |
| `algae`       | ![](images/colormaps/algae.png)       |
| `apricity`    | ![](images/colormaps/apricity.png)    |
| `arbre`       | ![](images/colormaps/arbre.png)       |
| `dusk`        | ![](images/colormaps/dusk.png)        |
| `kelp`        | ![](images/colormaps/kelp.png)        |
| `octarine`    | ![](images/colormaps/octarine.png)    |
| `pastel`      | ![](images/colormaps/pastel.png)      |
| `pixel_blue`  | ![](images/colormaps/pixel_blue.png)  |
| `pixel_green` | ![](images/colormaps/pixel_green.png) |
| `pixel_red`   | ![](images/colormaps/pixel_red.png)   |
| `xray`        | ![](images/colormaps/xray.png)        |

Table: Colormaps provided by `cmyt`. {#tbl:colormaps}

We note in particular that in previous versions of yt, `algae` was known as `bds_highcontrast` (and was our default colormap) and that the `arbre` colormap is the current default colormap.
`pastel` was designed by Tune Kamae, and was previously referred to as `kamae`.

### Enhanced Error Messages

Providing helpful error messages is almost an art form; projects like AstroPy @astropy5 have developed complex, helpful and thoughtfully-designed methods of providing as much usable information as possible when something "goes wrong."
In recent development history, we have spent a considerable amount of effort attempting to discern between errors that are "user-facing" and those that are strictly "internal."
"Internal" errors, for the most part, are often highly-unexpected; they may result from malformed data, or data that yt (and the developers) do not know to expect, or from general software defects.
"User-facing" errors are those that can be anticipated, and they are the errors for which we endeavor to provide helpful and extensive responses.

Among others, some of the most useful error messages that yt provides are those related to accessing fields and loading datasets.
For instance, accessing the field `"x_velocity"` instead of `"velocity_x"` will produce an error, suggesting the *correct* field to access.
When loading a dataset, yt will attempt to determine what the format of the data is; if it is unable to unambiguously identify the data format, it will provide an error message that shows the different options, and indicates how to disambiguate.

While these may seem like simple, obvious changes to make, they can hide difficult technical challenges, and more importantly, have dramatically improved the user experience for people using yt.

### Jupyter Integration {#sec:jupyter_integration}

Project Jupyter is an overarching term for a collection of related projects that provide an extensive, end-to-end suite for the user experience of developing code and narrative, as described in depth in (among other papers) @doi:10.1109/MCSE.2021.3059263 and @soton403913.
While many in the yt community utilize yt through python scripts executed on the command line or through submission queues on high-performance computing resources, a large fraction utilize Jupyter Notebooks for their data exploration.
In addition to enhancements in the user interface for unmodified Python libraries, Jupyter provides opportunities for libraries and applications to provide rich, enhanced interfaces with widgets, styling of text, complex layout and in-line visualizations.
An important aspect of Project Jupyter is the flexibility of the kernel system, which mediates communication between a frontend (often a web browser, but also a command-line application or native GUI) and a execution kernel, which can be running locally or on a remote resource.
This allows individuals to utilize a local web browser and execute their operations on remote resources; by means of its flexible transport layer, images and the like can be passed back to the web browser *inline* with the code that generated them, greatly speeding the process of examining and manipulating data.
For users of high-performance resources to which they do not have physical access, having visualizations inline with code can be transformative; rather than having toe `scp` or `rsync` plots back and forth to inspect, they are available with no additional steps.
Among the many different advantages that working in a Jupyter (Notebook) environment offers, this is perhaps the one that is the "stickiest" for researchers accustomed to working on systems without GUI toolkits installed by default, and the one that has led to the widespread adoption of Jupyter.
IPython, a Python-specific Jupyter subproject, also provides a number of quality-of-life improvements, such as tab-completion and "magic" commands that modify the interpretation and execution of code.

Under the broad umbrella of Project Jupyter is the [`ipywidgets`](https://github.com/jupyter-widgets/ipywidgets/) project.
The `ipywidgets` project provides GUI elements that are displayed in Jupyter Notebooks that are generated and represented by kernel-side Python code.
This allows a Python project to expose deeper information or interactive functionality without writing non-Python code, and also manages the data transport between the display and the kernel.

yt takes advantage of some of these facilities, particularly in those areas where users have in the past struggled with discoverability.
yt utilizes IPython tab-completion for field access on data objects, which greatly decreases the likelihood of typos for field *types* as well as field *names*.
This is generated on a per-dataset basis, to ensure that the fields are all specifically available for each individual dataset.
Providing tab-completion reduces the need for users to look up the full collection of fields (sorted by field type) before referencing them.
Because yt provides *so many* fields, in many cases with similar names, this substantially reduces the likelihood of typos and errors.

In addition to tab-completion, yt utilizes `ipywidgets` in two specific places.
The first of these is in display of three-element numerical fields; while this may seem like a rather niche application, these typically show up as properties of datasets that require unit conversion into meaningful values.
Many simulation codes in astrophysics, for instance, normalize the indexing units and then apply unit conversions to physical units.
All three-element numeric arrays associated with units are displayed as three (read-only) input boxes and a drop-down for unit conversion.

The other area that widgets are provided is in the field system.
Navigating the available fields (even mediated by tab-completion) can be overwhelming, and more importantly, ensuring that a field definition matches the expectations of a researcher is critical.
The fields widget, displayed whenever the `fields` attribute of a dataset is displayed, allows exploration of the field definitions, including the underlying source code, the expected units, display names, and so forth.
Because many of the fields in yt are defined programmatically, it also attempts to resolve variables defined in a closure.
For example, if the fields `momentum_x`, `momentum_y` and `momentum_z` are defined in a loop over the available axes (`x`, `y`, `z`), the source code explorer will attempt to show the loop variable's current value for each definition.

These are the built-in widgets in yt; in addition to these, the [`widgyts`](https://github.com/yt-project/widgyts) package (described in @doi:10.21105/joss.01774) provides a number of additional widgets.
Following the publication of its paper, it has expanded to include not only webassembly-based pixelization routines (to create in-browser 'slippy maps' of 2D data) but also PyThreeJS-based dataset exploration of simulations.
Packaging this separately from yt provides the opportunity for faster development and more experimental usage of external packages, but also greatly reduces discoverability and utilization.
We are exploring options for encouraging its uptake, particularly as we anticipate it will continue to grow and provide additional functionality.
